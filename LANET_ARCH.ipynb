{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_WxmVygaFhJ6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "STkoNYj1Fu07"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid_activation(x):\n",
        "    return x * torch.sigmoid(x)"
      ],
      "metadata": {
        "id": "Vhh37HzPGAHW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Modified Lanet Architecture**\n",
        "\n",
        "We used 3×3 filters instead of the original 5×5 filters to reduce the number of parameters while maintaining feature extraction power.\n",
        "\n",
        "Using MaxPooling instead of average pooling to retain important features.\n",
        "\n",
        "Softmax layer at the end to convert outputs into probabilities to make interpretation easier."
      ],
      "metadata": {
        "id": "YxrDDCzMI4Qu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ModifiedLeNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ModifiedLeNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 6, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(6, 16, kernel_size=3)\n",
        "        self.conv3 = nn.Conv2d(16, 120, kernel_size=3)\n",
        "        #using maxpool instead of average pool\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc1 = nn.Linear(120 * 4 * 4, 84)\n",
        "        self.fc2 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(sigmoid_activation(self.conv1(x)))\n",
        "        x = self.pool(sigmoid_activation(self.conv2(x)))\n",
        "        x = sigmoid_activation(self.conv3(x))\n",
        "        x = torch.flatten(x, start_dim=1)\n",
        "        x = sigmoid_activation(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        #returning after applying softmax\n",
        "        return F.softmax(x, dim=1)"
      ],
      "metadata": {
        "id": "MHKPwcfZH1Gi"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are using device **cuda**, Loss function **CrossEntropyLoss** and optimizer as **Adam**"
      ],
      "metadata": {
        "id": "KCdqLzekKZic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\")\n",
        "model = ModifiedLeNet().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "MySeFkMrIlN0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "    running_loss = 0.0\n",
        "    for images, labels in trainloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(trainloader):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sMalyO-IqRM",
        "outputId": "92dd57af-144f-4ebf-9226-ffeae8ddd1a0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 1.5543\n",
            "Epoch 2, Loss: 1.4882\n",
            "Epoch 3, Loss: 1.4799\n",
            "Epoch 4, Loss: 1.4764\n",
            "Epoch 5, Loss: 1.4744\n",
            "Epoch 6, Loss: 1.4732\n",
            "Epoch 7, Loss: 1.4728\n",
            "Epoch 8, Loss: 1.4712\n",
            "Epoch 9, Loss: 1.4708\n",
            "Epoch 10, Loss: 1.4707\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking the accuracy on the test data"
      ],
      "metadata": {
        "id": "r_0-pCV7LHj8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in testloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {100 * correct / total:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfVFeROUIvWC",
        "outputId": "4b03b19c-dc70-4d6e-b266-785d182d3369"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 98.77%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E-Da_V9-Os4R"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}